{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsh_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num hash tables: 1, feature = 1,024,000, jointhreshold = 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cf3937497174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Num hash tables: {num_hash_tables}, feature = {num_features:,.0f}, jointhreshold = {jointhreshold}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numFeatures\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0maccuracy_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/{path}.parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hash_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hashingtf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjointhreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0maccuracy_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_hash_tables\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_hash_tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0maccuracy_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jointhreshold\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjointhreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_projects/fellegi_sunter_em_spark/lsh_utils.py\u001b[0m in \u001b[0;36mrun_all\u001b[0;34m(path_to_data, num_hash_tables, feature_type, settings, threshold, spark)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mcomparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_comparisons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0maccuracy_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomparisons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_actual_comparisons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_projects/fellegi_sunter_em_spark/lsh_utils.py\u001b[0m in \u001b[0;36mget_accuracy_stats\u001b[0;34m(df, comparisons, num_actual_comparisons, spark)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"tp\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "counter = 1000\n",
    "path = \"fake_10000\"\n",
    "\n",
    "from pathlib import Path\n",
    "Path(f\"out_json_matrix/{path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for feature_type in [\"countvectorise\", \"hashingtf\", \"tfidf\"]\n",
    " \n",
    "ht_range = range(1,6)\n",
    "jt_range = [1.0, 0.6, 0.3]\n",
    "f_range = [1024000, 1024000*2, 1024000*4]\n",
    "\n",
    "for num_hash_tables in ht_range:\n",
    "    for jointhreshold in jt_range:\n",
    "        for num_features in f_range:\n",
    "            spark.catalog.clearCache()\n",
    "\n",
    "            # print(f\"*************\")\n",
    "            print(f\"Num hash tables: {num_hash_tables}, feature = {num_features:,.0f}, jointhreshold = {jointhreshold}\")\n",
    "            settings = {\"numFeatures\": num_features}\n",
    "            accuracy_stats = run_all(f\"data/{path}.parquet\", num_hash_tables, \"hashingtf\", settings, jointhreshold, spark)\n",
    "            accuracy_stats[\"num_hash_tables\"] = num_hash_tables\n",
    "            accuracy_stats[\"jointhreshold\"] = jointhreshold\n",
    "            accuracy_stats[\"num_features\"] = num_features\n",
    "            accuracy_stats[\"feature_type\"] = \"hashingtf\"\n",
    "\n",
    "            num_features_fn = f\"{num_features:,.5f}\".replace(\".\", \"p\")\n",
    "            jointhreshold_fn = f\"{jointhreshold:,.5f}\".replace(\".\", \"p\")\n",
    "\n",
    "            with open(f\"out_json_matrix/{path}/htf_{num_hash_tables}_{num_features_fn}_{jointhreshold_fn}_{counter}.json\", \"w\") as f:\n",
    "                json.dump(accuracy_stats, f)\n",
    "                \n",
    "#             ar = generate_report(accuracy_stats)\n",
    "#             print(ar)\n",
    "            counter +=1\n",
    "    \n",
    "for num_hash_tables in ht_range:\n",
    "    for jointhreshold in jt_range:\n",
    "        for num_features in f_range:\n",
    "            spark.catalog.clearCache()\n",
    "\n",
    "            # print(f\"*************\")\n",
    "            print(f\"Num hash tables: {num_hash_tables}, feature = {num_features:,.0f}, jointhreshold = {jointhreshold}\")\n",
    "            settings = {\"numFeatures\": num_features}\n",
    "            accuracy_stats = run_all(f\"data/{path}.parquet\", num_hash_tables, \"tfidf\", settings, jointhreshold, spark)\n",
    "            accuracy_stats[\"num_hash_tables\"] = num_hash_tables\n",
    "            accuracy_stats[\"jointhreshold\"] = jointhreshold\n",
    "            accuracy_stats[\"num_features\"] = num_features\n",
    "            accuracy_stats[\"feature_type\"] = \"tfidf\"\n",
    "\n",
    "            num_features_fn = f\"{num_features:,.5f}\".replace(\".\", \"p\")\n",
    "            jointhreshold_fn = f\"{jointhreshold:,.5f}\".replace(\".\", \"p\")\n",
    "\n",
    "            with open(f\"out_json_matrix/{path}/tfidf_{num_hash_tables}_{num_features_fn}_{jointhreshold_fn}_{counter}.json\", \"w\") as f:\n",
    "                json.dump(accuracy_stats, f)\n",
    "                \n",
    "#             ar = generate_report(accuracy_stats)\n",
    "#             print(ar)\n",
    "            counter +=1\n",
    "# [0.01*0.8**i for i in range(0,7)]\n",
    "# [0.999*0.4**i for i in range(0,6)]\n",
    "for num_hash_tables in ht_range:\n",
    "    for jointhreshold in jt_range:\n",
    "        for maxdf in [0.01*0.8**i for i in range(0,7)]:\n",
    "            spark.catalog.clearCache()\n",
    "\n",
    "            try:\n",
    "                print(f\"Num hash tables: {num_hash_tables}, maxdf = {maxdf:,.3f}, jointhreshold = {jointhreshold}\")\n",
    "                settings = {\"vocabSize\":10000,\"minTF\":1.0, \"maxDF\":maxdf, \"minDF\":2}\n",
    "                accuracy_stats = run_all(f\"data/{path}.parquet\", num_hash_tables, \"countvectorise\", settings, jointhreshold, spark)\n",
    "                accuracy_stats[\"num_hash_tables\"] = num_hash_tables\n",
    "                accuracy_stats[\"jointhreshold\"] = jointhreshold\n",
    "                accuracy_stats[\"maxdf\"] = maxdf\n",
    "                accuracy_stats[\"feature_type\"] = \"countvectoriser\"\n",
    "\n",
    "                max_df_fn = f\"{maxdf:,.5f}\".replace(\".\", \"p\")\n",
    "                jointhreshold_fn = f\"{jointhreshold:,.5f}\".replace(\".\", \"p\")\n",
    "\n",
    "                with open(f\"out_json_matrix/{path}/cv_{num_hash_tables}_{max_df_fn}_{jointhreshold_fn}_{counter}.json\", \"w\") as f:\n",
    "                    json.dump(accuracy_stats, f)\n",
    "                counter +=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num hash tables: 1, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 1, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 1, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 1, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 2, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 2, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 2, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 3, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 3, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 3, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 4, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 4, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 4, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.010, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.008, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.006, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.005, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.004, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 1.0\n",
      "Num hash tables: 5, maxdf = 0.010, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.008, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.006, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.005, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.004, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.6\n",
      "Num hash tables: 5, maxdf = 0.010, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.008, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.006, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.005, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.004, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.3\n",
      "Num hash tables: 5, maxdf = 0.003, jointhreshold = 0.3\n"
     ]
    }
   ],
   "source": [
    "for num_hash_tables in ht_range:\n",
    "    for jointhreshold in jt_range:\n",
    "        for maxdf in [0.01*0.8**i for i in range(0,7)]:\n",
    "            spark.catalog.clearCache()\n",
    "\n",
    "            try:\n",
    "                print(f\"Num hash tables: {num_hash_tables}, maxdf = {maxdf:,.3f}, jointhreshold = {jointhreshold}\")\n",
    "                settings = {\"vocabSize\":10000,\"minTF\":1.0, \"maxDF\":maxdf, \"minDF\":2}\n",
    "                accuracy_stats = run_all(f\"data/{path}.parquet\", num_hash_tables, \"cvidf\", settings, jointhreshold, spark)\n",
    "                accuracy_stats[\"num_hash_tables\"] = num_hash_tables\n",
    "                accuracy_stats[\"jointhreshold\"] = jointhreshold\n",
    "                accuracy_stats[\"maxdf\"] = maxdf\n",
    "                accuracy_stats[\"feature_type\"] = \"countvectoriser_with_idf\"\n",
    "\n",
    "                max_df_fn = f\"{maxdf:,.5f}\".replace(\".\", \"p\")\n",
    "                jointhreshold_fn = f\"{jointhreshold:,.5f}\".replace(\".\", \"p\")\n",
    "\n",
    "                with open(f\"out_json_matrix/{path}/cvidf_{num_hash_tables}_{max_df_fn}_{jointhreshold_fn}_{counter}.json\", \"w\") as f:\n",
    "                    json.dump(accuracy_stats, f)\n",
    "                counter +=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "for num_hash_tables in ht_range:\n",
    "    for jointhreshold in jt_range:\n",
    "        for maxdf in [0.01*0.8**i for i in range(0,7)]:\n",
    "            spark.catalog.clearCache()\n",
    "\n",
    "            try:\n",
    "                print(f\"Num hash tables: {num_hash_tables}, maxdf = {maxdf:,.3f}, jointhreshold = {jointhreshold}\")\n",
    "                settings = {\"vocabSize\":10000,\"minTF\":1.0, \"maxDF\":maxdf, \"minDF\":2}\n",
    "                accuracy_stats = run_all(f\"data/{path}.parquet\", num_hash_tables, \"countvectorise\", settings, jointhreshold, spark)\n",
    "                accuracy_stats[\"num_hash_tables\"] = num_hash_tables\n",
    "                accuracy_stats[\"jointhreshold\"] = jointhreshold\n",
    "                accuracy_stats[\"maxdf\"] = maxdf\n",
    "                accuracy_stats[\"feature_type\"] = \"countvectoriser\"\n",
    "\n",
    "                max_df_fn = f\"{maxdf:,.5f}\".replace(\".\", \"p\")\n",
    "                jointhreshold_fn = f\"{jointhreshold:,.5f}\".replace(\".\", \"p\")\n",
    "\n",
    "                with open(f\"out_json_matrix/{path}/cv_{num_hash_tables}_{max_df_fn}_{jointhreshold_fn}_{counter}.json\", \"w\") as f:\n",
    "                    json.dump(accuracy_stats, f)\n",
    "                counter +=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hash_tables = 5\n",
    "maxdf = 0.01  # 0.2 means filter out any tokens that appear in more than 20% of records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_and_process_fake_data(\"data/fake_10000.parquet\", spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = get_qgrams(df,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\"vocabSize\":10000,\"minTF\":1.0, \"maxDF\":maxdf, \"minDF\":2}\n",
    "features = get_features(\"countvectorise\", df_q, settings, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_model = get_lsh_model(num_hash_tables, features, spark)\n",
    "hash_values = lsh_model.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_groups = get_hash_groups(num_hash_tables, hash_values, spark)\n",
    "hash_groups.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_groups = list(hash_groups.limit(10).toPandas()[\"count_hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comparisons = get_num_comparisons(hash_groups, spark)\n",
    "hash_groups.unpersist()\n",
    "c = df.count()\n",
    "total_comparisons = c * (c-1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = get_comparisons(lsh_model, features, 1.0, spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "report = f\"\"\"\n",
    "You're making {num_comparisons:,.0f} from a total of {total_comparisons:,.0f} comparisons\n",
    "That's 1 comparison for every {total_comparisons/num_comparisons:,.1f} potential comparisons\n",
    "\n",
    "Sensitivity = {sensitivity:,.0%}\n",
    "Precision = {precision:,.0%}\n",
    "\n",
    "True positives  = {cc[\"tp\"]:,.0f}\n",
    "False positives = {cc[\"fp\"]:,.0f}\n",
    "True negatives  = {cc[\"tn\"]:,.0f}\n",
    "False negatives = {cc[\"fn\"]:,.0f}\n",
    "\n",
    "\"\"\"\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need high precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
